{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Table of Contents: </b>\n",
    "<br> [Pipeline 1](#11)\n",
    "<br> [Pipeline 2](#22)\n",
    "<br> [Pipeline 3](#33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "\n",
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets\n",
    "\n",
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"11\"> <h2> Pipeline 1 </h2> </a>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "# read csv file to a pandas dataframe\n",
    "df_pipeline1 = pd.read_csv(\"pipeline_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q1',\n",
       " 'VisitorType_New_Visitor',\n",
       " 'Informational_Duration_pp_iqr_yj_zscore',\n",
       " 'TrafficType_2',\n",
       " 'Browser_12',\n",
       " 'Q4',\n",
       " 'OperatingSystems_3',\n",
       " 'Browser_6',\n",
       " 'Month_Feb',\n",
       " 'ExitRates_iqr_yj_zscore',\n",
       " 'TrafficType_16',\n",
       " 'TrafficType_8',\n",
       " 'PageValues_iqr_yj_zscore',\n",
       " 'SpecialDay_0.8',\n",
       " 'OperatingSystems_7',\n",
       " 'TrafficType_20',\n",
       " 'TrafficType_13',\n",
       " 'TrafficType_3',\n",
       " 'Q3',\n",
       " 'TrafficType_1',\n",
       " 'SpecialDay_0.4',\n",
       " 'Administrative_Duration_iqr_yj_zscore']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract needed features as a list of columns \n",
    "# excluding target variable 'Revenue' and original object features (that were labelencoded), namely 'Month' and VisitorType'\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "## create a list of all the columns\n",
    "list_all_columns = df_pipeline1.columns.tolist()\n",
    "\n",
    "## remove features in list, which are not needed for testing for feature selection, namely:\n",
    "list_remove_features = ['Revenue'] \n",
    "\n",
    "# Create sets of a,b\n",
    "setA = set(list_all_columns)\n",
    "setB = set(list_remove_features)\n",
    "\n",
    "# Get new set with elements that are only in a but not in b\n",
    "setlist_X_columns = setA.difference(list_remove_features)\n",
    "\n",
    "# convert set object to a list\n",
    "list_X_columns = list(setlist_X_columns)\n",
    "\n",
    "# Define dependent variables\n",
    "X = df_pipeline1[list_X_columns].to_numpy()\n",
    "\n",
    "#show the columns that need to be included as features\n",
    "## sort alphabetically -- look up how to do this \n",
    "list_X_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Features and Target variables\n",
    "X = df_pipeline1[list_X_columns] # features vars\n",
    "y = df_pipeline1['Revenue'] # target vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2019) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93      3131\n",
      "           1       0.66      0.51      0.57       568\n",
      "\n",
      "    accuracy                           0.88      3699\n",
      "   macro avg       0.79      0.73      0.75      3699\n",
      "weighted avg       0.87      0.88      0.88      3699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check the predictive performance using the actual and predicted values\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"22\"> <h2> Pipeline 2 </h2> </a>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "# read csv file to a pandas dataframe\n",
    "df_pipeline2 = pd.read_csv(\"pipeline_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TrafficType_15',\n",
       " 'VisitorType_New_Visitor',\n",
       " 'TrafficType_2',\n",
       " 'Browser_12',\n",
       " 'Month_Mar',\n",
       " 'TrafficType_18',\n",
       " 'Month_Nov',\n",
       " 'OperatingSystems_3',\n",
       " 'Month_May',\n",
       " 'Month_Feb',\n",
       " 'ProductRelated_mm_yj_stdev',\n",
       " 'TrafficType_8',\n",
       " 'SpecialDay_0.8',\n",
       " 'PageValues_mm_yj_stdev',\n",
       " 'TrafficType_13',\n",
       " 'Administrative_Duration_mm_yj_stdev',\n",
       " 'TrafficType_3',\n",
       " 'Informational_mm_yj_stdev',\n",
       " 'TrafficType_1',\n",
       " 'add_exit_bounce_rates_mm_yj_stdev',\n",
       " 'TrafficType_12']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract needed features as a list of columns \n",
    "# excluding target variable 'Revenue' and original object features (that were labelencoded), namely 'Month' and VisitorType'\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "## create a list of all the columns\n",
    "list_all_columns = df_pipeline2.columns.tolist()\n",
    "\n",
    "## remove features in list, which are not needed for testing for feature selection, namely:\n",
    "list_remove_features = ['Revenue'] \n",
    "\n",
    "# Create sets of a,b\n",
    "setA = set(list_all_columns)\n",
    "setB = set(list_remove_features)\n",
    "\n",
    "# Get new set with elements that are only in a but not in b\n",
    "setlist_X_columns = setA.difference(list_remove_features)\n",
    "\n",
    "# convert set object to a list\n",
    "list_X_columns = list(setlist_X_columns)\n",
    "\n",
    "# Define dependent variables\n",
    "X = df_pipeline2[list_X_columns].to_numpy()\n",
    "\n",
    "#show the columns that need to be included as features\n",
    "## sort alphabetically -- look up how to do this \n",
    "list_X_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Features and Target variables\n",
    "X = df_pipeline2[list_X_columns] # features vars\n",
    "y = df_pipeline2['Revenue'] # target vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2019) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94      3131\n",
      "           1       0.68      0.55      0.61       568\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.80      0.75      0.77      3699\n",
      "weighted avg       0.88      0.89      0.89      3699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check the predictive performance using the actual and predicted values\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"33\"> <h2> Pipeline 3 </h2> </a>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "# read csv file to a pandas dataframe\n",
    "df_pipeline3 = pd.read_csv(\"pipeline_3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Declare Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PageValues_yj_stdev_zscore',\n",
       " 'Month_Nov',\n",
       " 'VisitorType_New_Visitor',\n",
       " 'TrafficType_15',\n",
       " 'TrafficType_2',\n",
       " 'TrafficType_3',\n",
       " 'Browser_12',\n",
       " 'Month_May',\n",
       " 'TrafficType_16',\n",
       " 'TrafficType_13',\n",
       " 'OperatingSystems_6',\n",
       " 'OperatingSystems_3',\n",
       " 'Browser_13',\n",
       " 'TrafficType_1',\n",
       " 'Month_Mar',\n",
       " 'SpecialDay_0.8',\n",
       " 'TrafficType_8',\n",
       " 'Month_Feb',\n",
       " 'Administrative_Duration_yj_stdev_zscore',\n",
       " 'Browser_6',\n",
       " 'OperatingSystems_7',\n",
       " 'ProductRelated_Duration_yj_stdev_zscore',\n",
       " 'Revenue']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show all columns in dataset\n",
    "list(df_pipeline3.columns)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TrafficType_15',\n",
       " 'PageValues_yj_stdev_zscore',\n",
       " 'VisitorType_New_Visitor',\n",
       " 'TrafficType_2',\n",
       " 'Browser_12',\n",
       " 'Month_Mar',\n",
       " 'Month_Nov',\n",
       " 'OperatingSystems_3',\n",
       " 'Browser_13',\n",
       " 'Month_May',\n",
       " 'Browser_6',\n",
       " 'Month_Feb',\n",
       " 'OperatingSystems_6',\n",
       " 'TrafficType_16',\n",
       " 'Administrative_Duration_yj_stdev_zscore',\n",
       " 'SpecialDay_0.8',\n",
       " 'TrafficType_8',\n",
       " 'OperatingSystems_7',\n",
       " 'ProductRelated_Duration_yj_stdev_zscore',\n",
       " 'TrafficType_13',\n",
       " 'TrafficType_3',\n",
       " 'TrafficType_1']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract needed features as a list of columns \n",
    "# excluding target variable 'Revenue' and original object features (that were labelencoded), namely 'Month' and VisitorType'\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "## create a list of all the columns\n",
    "list_all_columns = df_pipeline3.columns.tolist()\n",
    "\n",
    "## remove features in list, which are not needed for testing for feature selection, namely:\n",
    "list_remove_features = ['Revenue'] \n",
    "\n",
    "# Create sets of a,b\n",
    "setA = set(list_all_columns)\n",
    "setB = set(list_remove_features)\n",
    "\n",
    "# Get new set with elements that are only in a but not in b\n",
    "setlist_X_columns = setA.difference(list_remove_features)\n",
    "\n",
    "# convert set object to a list\n",
    "list_X_columns = list(setlist_X_columns)\n",
    "\n",
    "# Define dependent variables\n",
    "X = df_pipeline3[list_X_columns].to_numpy()\n",
    "\n",
    "#show the columns that need to be included as features\n",
    "## sort alphabetically -- look up how to do this \n",
    "list_X_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Features and Target variables\n",
    "X = df_pipeline3[list_X_columns] # features vars\n",
    "y = df_pipeline3['Revenue'] # target vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2019) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      3131\n",
      "           1       0.62      0.54      0.58       568\n",
      "\n",
      "    accuracy                           0.88      3699\n",
      "   macro avg       0.77      0.74      0.75      3699\n",
      "weighted avg       0.87      0.88      0.88      3699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check the predictive performance using the actual and predicted values\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
