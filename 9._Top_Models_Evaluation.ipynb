{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> Top Models Evaluation </b>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> The Top* 3 models are evaluated below, namely: </b>\n",
    "* Random Forest\n",
    "* Logistic Regression\n",
    "* XGBoost\n",
    "\n",
    "_* based on their respective f1-scores and AUC-scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Function for t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def my_t_test(a,b,size): # a, b are two arrays for comparison\n",
    "    n = size # size of the arrays\n",
    "\n",
    "    ## Calculate the Standard Deviation\n",
    "    var_a = a.var(ddof=1)\n",
    "    var_b = b.var(ddof=1)\n",
    "\n",
    "    #std deviation\n",
    "    s = np.sqrt((var_a + var_b)/2)\n",
    "\n",
    "    ## Calculate the t-statistics\n",
    "    t = (a.mean() - b.mean())/(s*np.sqrt(2/n))\n",
    "\n",
    "    ## Compare with the critical t-value\n",
    "    #Degrees of freedom\n",
    "    df = 2*n - 2\n",
    "\n",
    "    #p-value after comparison with the t \n",
    "    p = 1 - stats.t.cdf(t,df=df)  \n",
    "  \n",
    "    print(t, p)\n",
    "\n",
    "    if (abs(t) > 1.96) and p < 0.05:\n",
    "        return('mean of a and b are significantly different (reject H0)')\n",
    "    else:\n",
    "        return('mean of a and b are not significantly different (not reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# list f1 scores\n",
    "random_forest_f1_scores = np.array([0.88483129, 0.88614592, 0.89104629, 0.89328366, 0.88943046, 0.89933388,\n",
    " 0.89731823, 0.88379795, 0.89149793, 0.89761045])\n",
    "\n",
    "# list auc scores\n",
    "random_forest_auc_scores = np.array([0.91419658, 0.90797896, 0.91583495, 0.93737864, 0.91715366, 0.92299103,\n",
    " 0.94289314, 0.90924855, 0.92914382, 0.93649436])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_f1_scores = np.array([0.86467997, 0.88090757, 0.88221223, 0.88069853, 0.8858516,  0.8863854,\n",
    " 0.89028023, 0.86840567, 0.87598576, 0.8864023])\n",
    "xgboost_auc_scores = np.array([0.90930719, 0.91555045, 0.92187803, 0.93164666, 0.92176884, 0.93324737,\n",
    " 0.93881725, 0.91301319, 0.9191369,  0.93429295])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test difference between random forest and xgboost - f1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5862507930603744 0.0010553865827719333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mean of a and b are significantly different (reject H0)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_t_test(random_forest_f1_scores, xgboost_f1_scores, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test difference between random forest and xgboost - auc scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.10551912060736061 0.5414345452024795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mean of a and b are not significantly different (not reject H0)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_t_test(random_forest_auc_scores, xgboost_auc_scores, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_f1_scores = np.array([0.8894459,  0.89001603, 0.88029261, 0.91148607, 0.89387695, 0.90060235,\n",
    " 0.89136015, 0.88088811, 0.89507029, 0.90087893])\n",
    "\n",
    "lr_auc_scores = np.array([0.91488578, 0.93329738, 0.91995549, 0.93562364, 0.91613354, 0.9210405,\n",
    " 0.92940224, 0.92738434, 0.91595299, 0.92580348])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test difference between logistic regression and random forest - f1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5690149206117066 0.2881889904621324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mean of a and b are not significantly different (not reject H0)'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_t_test(lr_f1_scores, random_forest_f1_scores, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test difference between logistic regression and random forest - auc scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1342195652019725 0.4473591529657279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mean of a and b are not significantly different (not reject H0)'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_t_test(lr_auc_scores, random_forest_auc_scores, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check variance f1 scores top 3 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model variance (f1-score): 0.00522148693387849\n"
     ]
    }
   ],
   "source": [
    "print(\"model variance (f1-score):\", random_forest_f1_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model variance (f1-score): 0.007828226535137064\n"
     ]
    }
   ],
   "source": [
    "print(\"model variance (f1-score):\", xgboost_f1_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model variance (f1-score): 0.00893044817932051\n"
     ]
    }
   ],
   "source": [
    "print(\"model variance (f1-score):\", lr_f1_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check variance auc scores top 3 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model variance (ROC/AUC): 0.011827850464091471\n"
     ]
    }
   ],
   "source": [
    "print(\"model variance (ROC/AUC):\", random_forest_auc_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model variance (ROC/AUC): 0.009541568176939305\n"
     ]
    }
   ],
   "source": [
    "print(\"model variance (ROC/AUC):\", xgboost_auc_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model variance (ROC/AUC): 0.00707272890777923\n"
     ]
    }
   ],
   "source": [
    "print(\"model variance (ROC/AUC):\", lr_auc_scores.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
