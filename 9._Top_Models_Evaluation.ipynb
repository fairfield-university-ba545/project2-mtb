{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> Top Models Evaluation </b>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> The Top* 3 models are evaluated below, namely: </b>\n",
    "* Random Forest\n",
    "* Logistic Regression\n",
    "* XGBoost\n",
    "\n",
    "_* based on their respective f1-scores and AUC-scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left align all markdown tables with code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table {\n",
       "        display: inline-block\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "    table {\n",
    "        display: inline-block\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Model**           | **Avg Weighted  F1-score** | **AUC score** |\n",
    "|:-------------------:|:--------------------------:|:-------------:|\n",
    "| Logistic Regression | 0\\.8934\\*                  | 0\\.9239\\*     |\n",
    "| Random Forest       | 0\\.8914\\*                  | 0\\.9233\\*     |\n",
    "| XGBoost             | 0\\.8802\\*                  | 0\\.9239\\*     |\n",
    "\n",
    "\\* _Cross validation results (KFold=10) , with optimized hyper-parameters._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the scores listed above are similar, we perform a statistical test (t-test) to evaluate if the scores are significantly different from one another.\n",
    "<br> In case they are the same, we also evaluate the model with the lowest standard deviation in the weighted f1-scores and auc-scores based on our 10 split K-fold Cross Validation results.\n",
    "<br> These scores are obtained from the respective models, discussed in the previous chapters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Function for t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def my_t_test(a,b,size): # a, b are two arrays for comparison\n",
    "    n = size # size of the arrays\n",
    "\n",
    "    ## Calculate the Standard Deviation\n",
    "    var_a = a.var(ddof=1)\n",
    "    var_b = b.var(ddof=1)\n",
    "\n",
    "    #std deviation\n",
    "    s = np.sqrt((var_a + var_b)/2)\n",
    "\n",
    "    ## Calculate the t-statistics\n",
    "    t = (a.mean() - b.mean())/(s*np.sqrt(2/n))\n",
    "\n",
    "    ## Compare with the critical t-value\n",
    "    #Degrees of freedom\n",
    "    df = 2*n - 2\n",
    "\n",
    "    #p-value after comparison with the t \n",
    "    p = 1 - stats.t.cdf(t,df=df)  \n",
    "  \n",
    "    print('t-statistic:', t, 'p-value:', p)\n",
    "\n",
    "    if (abs(t) > 1.96) and p < 0.05:\n",
    "        return('mean of a and b are significantly different (reject H0)')\n",
    "    else:\n",
    "        return('mean of a and b are not significantly different (not reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# list f1 scores\n",
    "random_forest_f1_scores = np.array([0.88483129, 0.88614592, 0.89104629, 0.89328366, 0.88943046, 0.89933388,\n",
    " 0.89731823, 0.88379795, 0.89149793, 0.89761045])\n",
    "\n",
    "# list auc scores\n",
    "random_forest_auc_scores = np.array([0.91419658, 0.90797896, 0.91583495, 0.93737864, 0.91715366, 0.92299103,\n",
    " 0.94289314, 0.90924855, 0.92914382, 0.93649436])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_f1_scores = np.array([0.86467997, 0.88090757, 0.88221223, 0.88069853, 0.8858516,  0.8863854,\n",
    " 0.89028023, 0.86840567, 0.87598576, 0.8864023])\n",
    "xgboost_auc_scores = np.array([0.90930719, 0.91555045, 0.92187803, 0.93164666, 0.92176884, 0.93324737,\n",
    " 0.93881725, 0.91301319, 0.9191369,  0.93429295])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test difference between random forest and xgboost - f1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: 3.5862507930603744 p-value: 0.0010553865827719333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mean of a and b are significantly different (reject H0)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_t_test(random_forest_f1_scores, xgboost_f1_scores, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test difference between random forest and xgboost - auc scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -0.10551912060736061 p-value: 0.5414345452024795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mean of a and b are not significantly different (not reject H0)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_t_test(random_forest_auc_scores, xgboost_auc_scores, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_f1_scores = np.array([0.8894459,  0.89001603, 0.88029261, 0.91148607, 0.89387695, 0.90060235,\n",
    " 0.89136015, 0.88088811, 0.89507029, 0.90087893])\n",
    "\n",
    "lr_auc_scores = np.array([0.91488578, 0.93329738, 0.91995549, 0.93562364, 0.91613354, 0.9210405,\n",
    " 0.92940224, 0.92738434, 0.91595299, 0.92580348])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test difference between logistic regression and random forest - f1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: 0.5690149206117066 p-value: 0.2881889904621324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mean of a and b are not significantly different (not reject H0)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_t_test(lr_f1_scores, random_forest_f1_scores, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test difference between logistic regression and random forest - auc scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: 0.1342195652019725 p-value: 0.4473591529657279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mean of a and b are not significantly different (not reject H0)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_t_test(lr_auc_scores, random_forest_auc_scores, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check standard deviation f1-scores top 3 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model variance (f1-score): 0.00522148693387849\n"
     ]
    }
   ],
   "source": [
    "print(\"model variance (f1-score):\", random_forest_f1_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model variance (f1-score): 0.007828226535137064\n"
     ]
    }
   ],
   "source": [
    "print(\"model variance (f1-score):\", xgboost_f1_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model variance (f1-score): 0.00893044817932051\n"
     ]
    }
   ],
   "source": [
    "print(\"model variance (f1-score):\", lr_f1_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check standard deviation AUC-scores top 3 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model variance (ROC/AUC): 0.011827850464091471\n"
     ]
    }
   ],
   "source": [
    "print(\"model variance (ROC/AUC):\", random_forest_auc_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model variance (ROC/AUC): 0.009541568176939305\n"
     ]
    }
   ],
   "source": [
    "print(\"model variance (ROC/AUC):\", xgboost_auc_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model variance (ROC/AUC): 0.00707272890777923\n"
     ]
    }
   ],
   "source": [
    "print(\"model variance (ROC/AUC):\", lr_auc_scores.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
